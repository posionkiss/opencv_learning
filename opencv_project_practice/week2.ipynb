{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fc6855a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa2ac5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.namedWindow('window',cv2.WINDOW_NORMAL)\n",
    "pic=cv2.imread('../material/used/images/smile_face.png',1)\n",
    "cv2.resizeWindow('window',(pic.shape[1],pic.shape[0]))\n",
    "cv2.imshow('window',pic)\n",
    "\n",
    "while cv2.waitKey(0)!=ord('q'):\n",
    "    None\n",
    "cv2.destroyAllWindows()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41766b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "清晰度包括：亮度、对比度、尺寸大小、细微层次、颜色饱和度\n",
    "对比度=最大亮度/最小亮度\n",
    "\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e9f529dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(344, 693, 3)\n"
     ]
    }
   ],
   "source": [
    "print(pic.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c384c246",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "255\n"
     ]
    }
   ],
   "source": [
    "print(pic[10,50,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "78fbd839",
   "metadata": {},
   "outputs": [],
   "source": [
    "pic_1=pic[100:300,200:300]\n",
    "cv2.imshow('window',pic_1)\n",
    "while cv2.waitKey(0)!=ord('q'):\n",
    "    None\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "29d8de52",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pic_1=pic[:,:341]\n",
    "pic_2=pic[:,341:]\n",
    "\n",
    "cv2.imshow('pic_1',pic_1)\n",
    "cv2.imshow('pic_2',pic_2)\n",
    "while cv2.waitKey(0)!=ord('q'):\n",
    "    None\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "cv2.imwrite('../material/saved/pic_1.png',pic_1)\n",
    "cv2.imwrite('../material/saved/pic_2.png',pic_2)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "93c6d11f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B: 0   G:0   R: 255\n"
     ]
    }
   ],
   "source": [
    "pic=cv2.imread('../material/used/images/red.png')\n",
    "cv2.imshow('red',pic)\n",
    "print('B:',str(pic[1,1,0]),'  G:'+str(pic[1,1,1]),'  R:',str(pic[1,1,2]))\n",
    "while cv2.waitKey(0)!=ord('q'):\n",
    "    None\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "76512d0e",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]] [[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]] [[255 255 255 ... 255 255 255]\n",
      " [255 255 255 ... 255 255 255]\n",
      " [255 255 255 ... 255 255 255]\n",
      " ...\n",
      " [255 255 255 ... 255 255 255]\n",
      " [255 255 255 ... 255 255 255]\n",
      " [255 255 255 ... 255 255 255]]\n"
     ]
    }
   ],
   "source": [
    "b,g,r,=cv2.split(pic)\n",
    "print(b,g,r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "94363a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pic=cv2.imread('../material/used/images/smile_face.png',1)\n",
    "pic_1=pic[:,:341]\n",
    "pic_2=pic[:,341:]\n",
    "#pic_1_r=pic_1[:,:,1]\n",
    "#cv2.imshow('b',pic_1[:,:,0])\n",
    "#cv2.imshow('g',pic_1[:,:,1])\n",
    "cv2.imshow('r',pic_1[:,:,2])\n",
    "\n",
    "while cv2.waitKey(0)!=ord('q'):\n",
    "    None\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "747de162",
   "metadata": {},
   "outputs": [],
   "source": [
    "pic=cv2.imread('../material/used/images/shenzhen_gray.bmp',0)\n",
    "pic[pic>180]=0\n",
    "pic[pic<60]=0\n",
    "pic[pic!=0]=255\n",
    "cv2.imshow('pic',pic)\n",
    "\n",
    "while cv2.waitKey(0)!=ord('q'):\n",
    "    None\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "809defce",
   "metadata": {},
   "outputs": [],
   "source": [
    "pic_1=cv2.imread('../material/used/images/shenzhen_mask.bmp',0)\n",
    "pic=cv2.imread('../material/used/images/shenzhen_gray.bmp',0)\n",
    "pic_m=cv2.bitwise_or(pic,pic_1)\n",
    "cv2.imshow('pic_m',pic_m)\n",
    "\n",
    "while cv2.waitKey(0)!=ord('q'):\n",
    "    None\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1a2a8bae",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "only size-1 arrays can be converted to Python scalars",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [10]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m pic_2\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m/\u001b[39m(\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[43mmath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexp\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m0.04\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpic\u001b[49m\u001b[43m)\u001b[49m)\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m0.5\u001b[39m\n",
      "\u001b[1;31mTypeError\u001b[0m: only size-1 arrays can be converted to Python scalars"
     ]
    }
   ],
   "source": [
    "pic_2=math.(1+math.exp(-1*0.04*pic))-0.5"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py_opencv",
   "language": "python",
   "name": "opencv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
